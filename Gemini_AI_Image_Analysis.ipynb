{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlUp3kW7DA7H559q56od5U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pushyanth-sai/LMS-AD/blob/main/Gemini_AI_Image_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hHhrcDkOYcdn"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "from IPython.display import display, Markdown\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "0NSIj8TiZd6C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "img = PIL.Image.open('image1.jpg')\n",
        "img\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([\"Write a short, engaging blog post based on this picture.It should include a description of the  photo and talk about my journey meal prepping.\", img],\n",
        "stream=True)\n",
        "response.resolve()"
      ],
      "metadata": {
        "id": "VjQr6Q2LZr8C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "9BPk2aHAeJvh",
        "outputId": "2f00a04b-aff3-407f-ea7b-c36763a8c3d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> ## My Meal Prep Journey: From Chaos to Calm (and Delicious!)\n> \n> The picture says it all: two perfectly portioned containers overflowing with vibrant, healthy goodness.  Chicken, broccoli, carrots, and fluffy rice – my go-to meal prep recipe for the week.  It looks good enough to eat *right now*, doesn't it?\n> \n> For the longest time, my lunch routine was a frantic scramble between work meetings and questionable takeout choices.  I'd spend my lunch break stressing over food instead of enjoying it. It was unhealthy, expensive, and utterly unsustainable.\n> \n> Then, I decided enough was enough.  I embarked on my meal prep journey, and let me tell you, it's been transformative!\n> \n> The initial few weeks were a bit chaotic.  I overcooked things, under-seasoned others, and the portion sizes were all over the place.  But slowly, I found my rhythm.  I started experimenting with different recipes, learning what works for my schedule and palate.\n> \n> The benefits are undeniable.  Meal prepping saves me time and money. No more impulse fast food!  More importantly, it allows me to focus on eating healthier, more nutritious meals.  Knowing I have a healthy lunch waiting for me eliminates that afternoon slump and keeps me energized.\n> \n> It's not always easy. Some weeks are busier than others, and finding the time to cook can be a challenge. But the feeling of satisfaction when I open my fridge on Monday morning and see those colorful containers?  Totally worth it!\n> \n> What's your favorite meal prep recipe?  Share your tips and tricks in the comments below! Let's inspire each other to healthier, happier lunches.\n"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Generate an accurate caption for this image.\", img])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "h_UKbiAkeMKR",
        "outputId": "6eadcd43-326b-4e96-cead-59f03045920e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are a few caption options for the image:\n",
            "\n",
            "**Option 1 (Simple & Descriptive):**\n",
            "\n",
            "> Healthy and delicious meal prep!  Chicken, broccoli, carrots, and rice - perfect for a quick and nutritious lunch.\n",
            "\n",
            "\n",
            "**Option 2 (More Engaging):**\n",
            "\n",
            "> Lunch goals! ✨ These chicken and veggie bowls are packed with flavor and ready in minutes.  What's your favorite meal prep recipe?\n",
            "\n",
            "\n",
            "**Option 3 (Focus on Convenience):**\n",
            "\n",
            "> Easy meal prep made simple.  Grab-and-go lunches that are both healthy and satisfying.\n",
            "\n",
            "\n",
            "**Option 4 (Slightly More Formal):**\n",
            "\n",
            "> Two portions of a balanced meal featuring stir-fried chicken with broccoli, carrots, and rice. Prepared for convenient and healthy eating.\n",
            "\n",
            "\n",
            "Choose the caption that best suits your intended audience and platform.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "# Open an Image\n",
        "image_path = \"/content/girl.jpg\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "#Generate a description of the image\n",
        "response = model.generate_content([\"Describe this image in detail.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "mJcocB8TfJMH",
        "outputId": "9290c054-a75d-468a-aeb5-87c01262d112"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a description of the image:\n",
            "\n",
            "Close-up view of a woman with shoulder-length, curly brown hair. \n",
            "\n",
            "\n",
            "She is light-skinned and has a warm, friendly expression. Her eyes are dark, and she has a broad smile showing her teeth. She is wearing a teal blue, three-quarter sleeve top with a subtle gold pattern, possibly floral or paisley. The top appears to be made of a soft material. \n",
            "\n",
            "\n",
            "The woman's arms are crossed, and she is pointing with her index finger of her right hand towards something off-camera to her left, indicating or directing attention to something out of the frame.\n",
            "\n",
            "\n",
            "The background is a plain, bright white, which draws all the focus to the woman. The overall impression is one of a friendly, approachable, and perhaps informative image, possibly for advertising or a presentation.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"What emotions ca you detect in this image.\", img])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "YEx5FQY3hGwQ",
        "outputId": "a4b94c3f-e22a-46e2-b086-ad2bce6993bd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image evokes feelings of:\n",
            "\n",
            "* **Appetite/Hunger:** The vibrant colors and appetizing presentation of the food are designed to stimulate hunger.\n",
            "* **Health/Well-being:** The meal appears healthy and balanced, suggesting feelings of well-being and care for one's health.\n",
            "* **Preparation/Organization:** The food is neatly packed in containers, implying a sense of organization and preparedness.\n",
            "* **Calm/Serenity:** The overall aesthetic is clean and simple, promoting a sense of calm and peace.\n",
            "\n",
            "\n",
            "It's important to note that these are inferred emotions based on the visual cues of the image.  There are no actual people present to experience and express emotions directly.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path =\"/content/quote.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Extract and read the text from this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "uxJJSdAOirzV",
        "outputId": "c651e7d8-13ba-42e1-9ae7-a88912b97ec0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's the text from the image:\n",
            "\n",
            "FAILURE is not the\n",
            "opposite of success\n",
            "it's PART OF\n",
            "SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = '/content/logo1.jpg'\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Describe this image in detail.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "k3YfYP7RkYK5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "2162bf34-01e3-4ca6-c028-ebda0effb4a5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's the logo for Amazon. \n",
            "\n",
            "\n",
            "The image shows the word \"amazon\" in a bold, black sans-serif font.  Below the word is a stylized orange smile, which is a key element of the Amazon logo. The background is transparent, allowing the logo to be placed on other images or backgrounds without interference.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"What emotions can you detect in this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "trkguhk4SsSp",
        "outputId": "0974aa96-a901-4391-a607-e0a0aebf5785"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Amazon logo itself doesn't evoke specific emotions.  Logos are designed to be recognizable and associated with a brand, not to directly trigger emotional responses.  However, *people's associations* with Amazon might elicit a range of emotions depending on their experiences:\n",
            "\n",
            "* **Positive:** Trust, convenience, satisfaction (if they've had good experiences), excitement (anticipation of a delivery), relief (finding a product easily).\n",
            "* **Negative:** Frustration, anger (due to bad customer service, late deliveries, or price increases), anxiety (regarding data privacy), disappointment (with product quality).\n",
            "* **Neutral:**  Indifference, familiarity.\n",
            "\n",
            "\n",
            "The logo itself is simply a visual representation of the brand; the emotions are projected onto it by the individual viewer based on their personal relationship with the company.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = '/content/product.jpg'\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Suggest similar products to this one.\", image])\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "BUGOxBatS6kC",
        "outputId": "b2fb4d7c-145e-423a-d320-57dc0e9cb430"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some similar products to the pictured black over-ear headphones:\n",
            "\n",
            "**Focusing on Style and Features:**\n",
            "\n",
            "* **Other Over-Ear Headphones:**  Look for other black over-ear headphones from brands like Sony, Bose, Sennheiser, JBL, Audio-Technica, AKG, Beats, and Anker.  Consider features important to you, such as noise cancellation, wireless capability (Bluetooth), foldable design for portability, and microphone quality.\n",
            "\n",
            "* **Similar Design Aesthetics:** Search for headphones with a similar sleek, minimalist design.  Keywords to use in your search include \"over-ear,\" \"closed-back\" (as these appear to be), \"black headphones,\" \"minimalist headphones,\" and \"premium headphones.\"\n",
            "\n",
            "**Focusing on Specific Features (if applicable):**\n",
            "\n",
            "* **Noise-Cancelling Headphones:** If noise cancellation is a key feature, specify this in your search.  Many brands offer high-quality noise-canceling over-ear headphones.\n",
            "\n",
            "* **Wireless Headphones:** If wireless is essential, look for Bluetooth headphones with a specified Bluetooth version (e.g., Bluetooth 5.0 or later) for better connectivity and range.\n",
            "\n",
            "* **Wired Headphones:** If wired is preferred, ensure the headphone jack type matches your device (e.g., 3.5mm).\n",
            "\n",
            "* **Headphones with a Microphone:** If you need a built-in microphone for calls or voice assistants, make sure this is specified in your search criteria.\n",
            "\n",
            "\n",
            "**Where to Search:**\n",
            "\n",
            "* **Major Online Retailers:** Amazon, Best Buy, Walmart, Target\n",
            "* **Electronics Specialists:** Crutchfield, Adorama\n",
            "* **Manufacturer Websites:**  Check the websites of the brands mentioned above.\n",
            "\n",
            "\n",
            "Remember to read reviews before purchasing to get a sense of the sound quality, comfort, and durability of different headphones.  The image alone doesn't reveal all the specifications of the headphones.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = '/content/invoice.jpg'\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Extract the price, currency, and any discounts from this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "z6SsJNgwTYcQ",
        "outputId": "249f6109-5ae3-4d71-98a9-b4138a6040c8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's the extracted information from the provided invoice image:\n",
            "\n",
            "* **Price:** $10.00 (for each item)\n",
            "* **Currency:** USD (indicated by the dollar sign $)\n",
            "* **Discounts:** No discounts are listed on the invoice.  The total is $100.00, and a 10% tax is added which results in a final total of $100.00.  This means that there are no discounts applied before the tax is calculated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = '/content/items.jpg'\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"List all objects in this image and count how many of each are present.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "CxmLRKgXThAV",
        "outputId": "18007b66-cf1b-477c-e4c2-6704a4eaeec6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a count of the objects in the image:\n",
            "\n",
            "**Countables:**\n",
            "\n",
            "* Eggs: 3\n",
            "* Banana: 1\n",
            "* Olives: 2\n",
            "* Fries: 1 (portion)\n",
            "* Burger: 1\n",
            "* Hot dog: 1\n",
            "* Apple: 1\n",
            "* Carrots: 2\n",
            "* Tomatoes: 3\n",
            "* Watermelon: 1\n",
            "\n",
            "\n",
            "**Uncountables:**\n",
            "\n",
            "* Milk: 1 (bottle)\n",
            "* Flour: 1 (bag)\n",
            "* Salt: 1 (container)\n",
            "* Sugar: 1 (container)\n",
            "* Jam: 1 (jar)\n",
            "* Meat: 2 (slices)\n",
            "* Rice: 1 (pile)\n",
            "* Honey: 1 (jar)\n",
            "* Tea: 1 (cup)\n",
            "* Cheese: 1 (slice)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install youtube-transcript-api pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qakfYjwUkuq",
        "outputId": "de8810a2-3e72-4dd1-d4f3-4e713d9bcf47"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.11/dist-packages (15.0.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "def get_youtube_transcript(video_url):\n",
        "    \"\"\"Fetches the transcript of a YouTube video.\"\"\"\n",
        "    video_id = video_url.split(\"v=\")[1].split(\"&\")[0]  # Extract video ID\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "    full_text = \" \".join([t[\"text\"] for t in transcript])\n",
        "    return full_text\n",
        "video_url = \"https://www.youtube.com/watch?v=unYDoA8QGH0&list=PLWEpztHwA4ZT2QlHC74oIz4MsawcvE-QX\"\n",
        "video_transcript = get_youtube_transcript(video_url)\n",
        "print(\"Transcript:\\n\", video_transcript[:500])"
      ],
      "metadata": {
        "id": "Jr1O1jmhVGIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure Gemini API\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "NGvtDLCCVKVC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_video_insights(text):\n",
        "    \"\"\"Extracts key insights from the YouTube video transcript.\"\"\"\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    prompt = f\"Extract the key takeaways and insights from this YouTube video:\\n\\n{text}\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "insights = extract_video_insights(video_transcript)\n",
        "print(\"Key Insights:\\n\", insights)"
      ],
      "metadata": {
        "id": "SQWMK7-zYjRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FZEPoi5WYmwv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}